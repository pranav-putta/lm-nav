Traceback (most recent call last):
  File "/coc/testnvme/pputta7/projects/lm-nav/lmnav/bc_train.py", line 296, in <module>
    trainer.eval_checkpoint(None)
  File "/coc/testnvme/pputta7/projects/lm-nav/lmnav/bc_train.py", line 293, in main
    def main():
  File "/coc/testnvme/pputta7/projects/lm-nav/lmnav/bc_train.py", line 220, in train
    stats = self.train_epoch(epoch)
  File "/coc/testnvme/pputta7/projects/lm-nav/lmnav/bc_train.py", line 178, in train_epoch
    outputs = self.agent(rgbs_t, goals_t, actions_t)
  File "/coc/testnvme/pputta7/mambaforge/envs/lmnav/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/coc/testnvme/pputta7/mambaforge/envs/lmnav/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1156, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/coc/testnvme/pputta7/mambaforge/envs/lmnav/lib/python3.9/site-packages/torch/nn/parallel/distributed.py", line 1110, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])  # type: ignore[index]
  File "/coc/testnvme/pputta7/mambaforge/envs/lmnav/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/coc/testnvme/pputta7/projects/lm-nav/lmnav/models/lin_nav_llama.py", line 262, in forward
    outputs = self.llama_model(inputs_embeds=embd,
  File "/coc/testnvme/pputta7/mambaforge/envs/lmnav/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/coc/testnvme/pputta7/projects/lm-nav/lmnav/models/modeling_llama.py", line 676, in forward
    outputs = self.model(
  File "/coc/testnvme/pputta7/mambaforge/envs/lmnav/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/coc/testnvme/pputta7/projects/lm-nav/lmnav/models/modeling_llama.py", line 565, in forward
    layer_outputs = decoder_layer(
  File "/coc/testnvme/pputta7/mambaforge/envs/lmnav/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/coc/testnvme/pputta7/projects/lm-nav/lmnav/models/modeling_llama.py", line 275, in forward
    hidden_states, self_attn_weights, present_key_value = self.self_attn(
  File "/coc/testnvme/pputta7/mambaforge/envs/lmnav/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/coc/testnvme/pputta7/projects/lm-nav/lmnav/models/modeling_llama.py", line 187, in forward
    query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin, position_ids)
  File "/coc/testnvme/pputta7/projects/lm-nav/lmnav/models/modeling_llama.py", line 121, in apply_rotary_pos_emb
    q_embed = (q * cos) + (rotate_half(q) * sin)
  File "/coc/testnvme/pputta7/projects/lm-nav/lmnav/models/modeling_llama.py", line 113, in rotate_half
    return torch.cat((-x2, x1), dim=-1)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 44.39 GiB total capacity; 30.70 GiB already allocated; 8.44 MiB free; 31.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF