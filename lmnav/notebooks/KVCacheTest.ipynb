{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dafc918-4799-485e-b3d2-a53ec6eabe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/coc/testnvme/pputta7/mambaforge/envs/lmnav/lib/python3.9/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-13 17:38:17,054] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e068bfb8e6674581b4517fc4c9bb18ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c197833b111140808b642d157badb8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f3aa8b9-7670-445d-b23c-e858262814f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f63d4ec0fd0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cuda\")\n",
    "seqs = [\"Hello my name is\", \"What\"]\n",
    "inputs = tokenizer(seqs)\n",
    "\n",
    "# pad with bos token on the left\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6bd915cb-de00-4680-b8be-db9dd157dedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s> Hello my name is', '<s> What']\n",
      "[[1, 15043, 590, 1024, 338], [1, 1724]]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(inputs['input_ids'], skip_special_tokens=False))\n",
    "print(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "77e14194-fecd-48e6-b2e2-295d10e38e5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "inps0 = torch.tensor(inputs['input_ids'][0])[None, :]\n",
    "inps1 = torch.tensor(inputs['input_ids'][1])[None, :]\n",
    "out0 = model(input_ids=inps0.cuda()).logits\n",
    "out1 = model(input_ids=inps1.cuda()).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2d5c3691-3e58-4f35-84cd-e655ffecf44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_batched_inp0 = inps0\n",
    "naive_batched_inp1 = torch.nn.functional.pad(inps1, (3, 0), mode=\"constant\", value=1)\n",
    "naive_batched_inp = torch.cat([naive_batched_inp0, naive_batched_inp1], dim=0)\n",
    "naive_batched_out = model(input_ids=naive_batched_inp.cuda()).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6ceff858-2c2a-4436-aa56-7dc870e1a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(out0[0], naive_batched_out[0], atol=1e-04, rtol=1e-05)\n",
    "assert not torch.allclose(out1[0], naive_batched_out[1,3:], atol=1e-04, rtol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "60b07e25-7594-4567-818b-debb19e11a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_inp0 = inps0\n",
    "batched_inp1 = torch.nn.functional.pad(inps1, (3, 0), mode=\"constant\", value=1)\n",
    "\n",
    "pos_ids = torch.tensor([[0, 1, 2, 3, 4], [0, 0, 0, 1, 2]]).cuda()\n",
    "attn_mask = torch.tensor([[1, 1, 1, 1, 1], [0, 0, 1, 1, 1]]).cuda()\n",
    "\n",
    "batched_inp = torch.cat([batched_inp0, batched_inp1], dim=0)\n",
    "batched_out = model(input_ids=naive_batched_inp.cuda(),\n",
    "                   position_ids=pos_ids,\n",
    "                   attention_mask=attn_mask).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "415e6e6e-db8f-418d-af79-f2895f438303",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(out0[0], batched_out[0], atol=1e-04, rtol=1e-05)\n",
    "assert not torch.allclose(out1[0], batched_out[1,3:], atol=1e-04, rtol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3fe45f65-663a-4a6d-b0fa-53f4c4767215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-12.9832,  -7.4134,  -0.4327,  ...,  -6.8297,  -8.0879,  -7.5863],\n",
       "        [-12.6002,  -9.4469,  -2.6035,  ...,  -7.0415,  -9.5093,  -9.2344]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0e632beb-6888-49ab-89ca-8482e29e043e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-12.9832,  -7.4134,  -0.4327,  ...,  -6.8297,  -8.0879,  -7.5863],\n",
       "        [-12.2200,  -8.4223,  -2.0610,  ...,  -6.8798,  -9.4445,  -8.9009]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batched_out[1, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70eefd88-2f07-47a5-813b-c81171322f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a50b72-09e6-497d-8435-fbc4adfa5a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
