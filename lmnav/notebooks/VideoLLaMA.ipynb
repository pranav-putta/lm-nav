{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f73fe1-e750-463f-9488-c1b99ab40df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/coc/testnvme/pputta7/mambaforge/envs/videollama/lib/python3.9/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n",
      "/coc/testnvme/pputta7/mambaforge/envs/videollama/lib/python3.9/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  warnings.warn(\n",
      "/coc/testnvme/pputta7/mambaforge/envs/videollama/lib/python3.9/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from video_llama.common.config import Config\n",
    "from video_llama.common.dist_utils import get_rank\n",
    "from video_llama.common.registry import registry\n",
    "from video_llama.conversation.conversation_video import Chat, Conversation, default_conversation,SeparatorStyle,conv_llava_llama_2\n",
    "\n",
    "#%%\n",
    "# imports modules for registration\n",
    "from video_llama.datasets.builders import *\n",
    "from video_llama.models import *\n",
    "from video_llama.processors import *\n",
    "from video_llama.runners import *\n",
    "from video_llama.tasks import *\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('/srv/flash1/pputta7/projects/lm-nav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9264b57c-dbd7-409c-90df-d72267d3eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.cfg_path = \"Video-LLaMA/eval_configs/video_llama_eval_only_vl.yaml\"\n",
    "        self.model_type = \"llama_v2\"\n",
    "        self.gpu_id = 0\n",
    "        self.options = []\n",
    "\n",
    "args = Args()\n",
    "cfg = Config(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d90868f-595b-4768-9f8b-d330c3a7ac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VIT\n",
      "Loading VIT Done\n",
      "Loading Q-Former\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21626e381574f2ba2239bd354e9f8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load first Checkpoint: ckpt/VL_LLaMA_2_7B_Finetuned.pth\n",
      "Initialization Finished\n"
     ]
    }
   ],
   "source": [
    "model_config = cfg.model_cfg\n",
    "model_cls = registry.get_model_class(model_config.arch)\n",
    "model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))\n",
    "model.eval()\n",
    "vis_processor_cfg = cfg.datasets_cfg.webvid.vis_processor.train\n",
    "vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)\n",
    "chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id))\n",
    "print('Initialization Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "59abe763-7d7d-4c36-8ba6-4d283b79f2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.mp4\n"
     ]
    }
   ],
   "source": [
    "chat_state = conv_llava_llama_2.copy()\n",
    "chat_state.system =  \"You are able to understand the visual content that the user provides.\\\n",
    "You are a navigational robot with egocentric vision that chooses the next action by choosing from {LEFT, RIGHT, FORWARD}.\\\n",
    "At every step, you receive a video from the previous action. You should describe what you see from the \\\n",
    "visual content and then provide the next action. You are looking for a washing machine. Apply STOP when you see it.\"\n",
    "img_list = []\n",
    "llm_message = chat.upload_video_without_audio(\"output.mp4\", chat_state, img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "84af1495-7440-412a-ad10-494474baa8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = \"Describe what happened briefly.\"\n",
    "chat.ask(user_message, chat_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e23f5d3-7b3c-49f5-9f6f-f6d1188bf5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are able to understand the visual content that the user provides.You are a navigational robot with egocentric vision that chooses the next action by choosing from {LEFT, RIGHT, FORWARD}.At every step, you receive a video from the previous action. You should describe what you see from the visual content and then provide the next action. You are looking for a washing machine. Apply STOP when you see it.\n",
      "<</SYS>>\n",
      "\n",
      "<Video><ImageHere></Video> The video contains 8 frames sampled at 0.0, 0.1, 0.2, 0.4, 0.5, 0.6, 0.8, 0.9 seconds.  Describe what happened briefly. [/INST] Sure! In the video, we see a room with a white door, a white wall, and a window. There is a white fridge and a white table in the room as well. The room has a mix of vintage and modern decor, with old photographs and a clock on the wall. We can also see a guitar on the wall and a white chair in the room. The room is relatively small, and we can see a small table with a lamp on it. </s>\n"
     ]
    }
   ],
   "source": [
    "llm_message = chat.answer(conv=chat_state,\n",
    "                              img_list=img_list,\n",
    "                              num_beams=1,\n",
    "                              temperature=0.6,\n",
    "                              max_new_tokens=600,\n",
    "                              max_length=2000)[0]\n",
    "print(chat_state.get_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9f7e7621-9b21-43fa-8955-c0b30e52a796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are able to understand the visual content that the user provides.You are a navigational robot with egocentric vision that chooses the next action by choosing from {LEFT, RIGHT, FORWARD}.At every step, you receive a video from the previous action. You should describe what you see from the visual content and then provide the next action. You are looking for a washing machine. Apply STOP when you see it.\n",
      "<</SYS>>\n",
      "\n",
      "<Video><ImageHere></Video> The video contains 8 frames sampled at 0.0, 0.1, 0.2, 0.4, 0.5, 0.6, 0.8, 0.9 seconds.  Describe what happened briefly. [/INST] Sure! In the video, we see a room with a white door, a white wall, and a window. There is a white fridge and a white table in the room as well. The room has a mix of vintage and modern decor, with old photographs and a clock on the wall. We can also see a guitar on the wall and a white chair in the room. The room is relatively small, and we can see a small table with a lamp on it. </s><s>[INST] Should you take a left, right, or go forward? [/INST] Since we are looking for a washing machine, I think it's best to take a right turn. There is a possibility that the washing machine is located in the next room, and we can see more of the room by turning right. </s>\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Should you take a left, right, or go forward?\"\n",
    "chat.ask(user_message, chat_state)\n",
    "llm_message = chat.answer(conv=chat_state,\n",
    "                              img_list=img_list,\n",
    "                              num_beams=1,\n",
    "                              temperature=0.8,\n",
    "                              max_new_tokens=700,\n",
    "                              max_length=2000)[0]\n",
    "print(chat_state.get_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "972f647d-f77b-42db-941d-94aaf01998b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output.mp4\n"
     ]
    }
   ],
   "source": [
    "llm_message = chat.upload_video_without_audio(\"output.mp4\", chat_state, img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "995f8535-76ae-468a-915b-872c89ebed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are able to understand the visual content that the user provides.You are a navigational robot with egocentric vision that chooses the next action by choosing to move towards an object in its vision.At every step, you receive a video from the previous action. You should describe what you see from thevisual content and then provide the next action. You are looking for a washing machine. Apply STOP when you see it.\n",
      "<</SYS>>\n",
      "\n",
      "<Video><ImageHere></Video> The video contains 8 frames sampled at 0.0, 0.1, 0.2, 0.4, 0.5, 0.6, 0.8, 0.9 seconds.  Describe what happened briefly. [/INST] First, I see a room with a white door and several pictures hanging on the wall. There is also a white chair in the room. Next, I see a room with a white door and a picture hanging on the wall. The room is decorated with a vase on the coffee table. Then, I see a room with a white door and a picture hanging on the wall. The room has a vase on the coffee table and a white chair. After that, I see a room with a white door and a picture hanging on the wall. The room has a vase on the coffee table and a white chair. Next, I see a room with a white door and a picture hanging on the wall. The room has a vase on the coffee table and a white chair. Finally, I see a room with a white door and a picture hanging on the wall. The room has a vase on the coffee table and a white chair. I will continue to look for a washing machine in the room. </s><s>[INST] Should you take a left, right, or go forward? [/INST] I will continue to move forward as I see a washing machine in the room. </s><s>[INST] <Video><ImageHere></Video> The video contains 8 frames sampled at 0.0, 0.1, 0.2, 0.4, 0.5, 0.6, 0.8, 0.9 seconds.  Describe the next scene [/INST] Next, I see a room with a white door and a picture hanging on the wall. There is also a small vase on the coffee table and a white chair in the room. The room is decorated with a black and white picture and a vase on the table. Finally, I see a room with a white door and a picture hanging on the wall. The room has a vase on the coffee table and a white chair. There is also a black and white picture hanging on the wall. I will continue to look for a washing machine in the room. </s>\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Describe the next scene\"\n",
    "chat.ask(user_message, chat_state)\n",
    "llm_message = chat.answer(conv=chat_state,\n",
    "                              img_list=img_list,\n",
    "                              num_beams=1,\n",
    "                              temperature=0.8,\n",
    "                              max_new_tokens=700,\n",
    "                              max_length=2000)[0]\n",
    "print(chat_state.get_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7a838b85-e358-46d8-91e9-4a3413fda5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST] <<SYS>>\n",
      "You are able to understand the visual content that the user provides.You are a navigational robot with egocentric vision that chooses the next action by choosing to move towards an object in its vision.At every step, you receive a video from the previous action. You should describe what you see from thevisual content and then provide the next action. You are looking for a washing machine. Apply STOP when you see it.\n",
      "<</SYS>>\n",
      "\n",
      "<Video><ImageHere></Video> The video contains 8 frames sampled at 0.0, 0.1, 0.2, 0.4, 0.5, 0.6, 0.8, 0.9 seconds.  Describe what happened briefly. [/INST] First, I see a room with a white door and several pictures hanging on the wall. There is also a white chair in the room. Next, I see a room with a white door and a picture hanging on the wall. The room is decorated with a vase on the coffee table. Then, I see a room with a white door and a picture hanging on the wall. The room has a vase on the coffee table and a white chair. After that, I see a room with a white door and a picture hanging on the wall. The room has a vase on the coffee table and a white chair. Next, I see a room with a white door and a picture hanging on the wall. The room has a vase on the coffee table and a white chair. Finally, I see a room with a white door and a picture hanging on the wall. The room has a vase on the coffee table and a white chair. I will continue to look for a washing machine in the room. </s><s>[INST] Should you take a left, right, or go forward? [/INST] I will continue to move forward as I see a washing machine in the room. </s><s>[INST] <Video><ImageHere></Video> The video contains 8 frames sampled at 0.0, 0.1, 0.2, 0.4, 0.5, 0.6, 0.8, 0.9 seconds.  Describe the next scene [/INST] Next, I see a room with a white door and a picture hanging on the wall. There is also a small vase on the coffee table and a white chair in the room. The room is decorated with a black and white picture and a vase on the table. Finally, I see a room with a white door and a picture hanging on the wall. The room has a vase on the coffee table and a white chair. There is also a black and white picture hanging on the wall. I will continue to look for a washing machine in the room. </s><s>[INST] Should you take a left, right, or go forward? [/INST] I will continue to move forward as I see a washing machine in the room. </s>\n"
     ]
    }
   ],
   "source": [
    "user_message = \"Should you take a left, right, or go forward?\"\n",
    "chat.ask(user_message, chat_state)\n",
    "llm_message = chat.answer(conv=chat_state,\n",
    "                              img_list=img_list,\n",
    "                              num_beams=1,\n",
    "                              temperature=0.8,\n",
    "                              max_new_tokens=700,\n",
    "                              max_length=2000)[0]\n",
    "print(chat_state.get_prompt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd8acb-dedc-48f3-bc1d-c4ed0e56130c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
